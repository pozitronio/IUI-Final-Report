{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import bz2 \n",
    "import re # regular expressions\n",
    "import random\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File(r'train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File(r'test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lines = train_file.readlines()\n",
    "test_file_lines = test_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary data to relief memory\n",
    "del train_file, test_file\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert from raw binary strings to strings that can be parsed\n",
    "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
    "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_file_lines) \n",
    "random.shuffle(test_file_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the size of the dataset\n",
    "train_set = train_file_lines[:10000]\n",
    "test_set = test_file_lines[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set[257])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary data\n",
    "del train_file_lines, test_file_lines\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting labels from the dataset\n",
    "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_set]\n",
    "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0s and 1s\n",
    "Y_train = pd.DataFrame(train_labels)\n",
    "Y_test = pd.DataFrame(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing labels and \\n from dataset and keeping the actual reviews\n",
    "train_reviews = [x.split(' ', 1)[1][:-1] for x in train_set]\n",
    "test_reviews = [x.split(' ', 1)[1][:-1] for x in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing URLs from reviews\n",
    "for i in range(len(train_reviews)):\n",
    "    if 'www.' in train_reviews[i] or 'http:' in train_reviews[i] or 'https:' in train_reviews[i] or '.com' in train_reviews[i]:\n",
    "        train_reviews[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"\", train_reviews[i])\n",
    "\n",
    "for i in range(len(test_reviews)):\n",
    "    if 'www.' in test_reviews[i] or 'http:' in test_reviews[i] or 'https:' in test_reviews[i] or '.com' in test_reviews[i]:\n",
    "        test_reviews[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"\", test_reviews[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing numbers from reviews\n",
    "for i in range(len(train_reviews)):\n",
    "    train_reviews[i] = re.sub(r'[0-9]+', '', train_reviews[i])\n",
    "for i in range(len(test_reviews)):\n",
    "    test_reviews[i] = re.sub(r'[0-9]+', '', test_reviews[i])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuations from reviews\n",
    "for i in range(len(train_reviews)):\n",
    "    train_reviews[i] = re.sub(r'[^\\w\\s]', '', train_reviews[i])\n",
    "for i in range(len(test_reviews)):\n",
    "    test_reviews[i] = re.sub(r'[^\\w\\s]', '', test_reviews[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews[456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer technique\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Without stop_words and stemming\n",
    "cv1 = CountVectorizer()\n",
    "\n",
    "# With stop_words\n",
    "cv2 = CountVectorizer(analyzer = 'word',stop_words='english')\n",
    "\n",
    "# With stemming\n",
    "import nltk.stem\n",
    "\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "class StemmedCountVectorizer_train(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer_train, self).build_analyzer()\n",
    "        return lambda train_reviews: ([stemmer.stem(w) for w in analyzer(train_reviews)])\n",
    "\n",
    "class StemmedCountVectorizer_test(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer_test, self).build_analyzer()\n",
    "        return lambda test_reviews: ([stemmer.stem(w) for w in analyzer(test_reviews)])    \n",
    "\n",
    "cv3_train = StemmedCountVectorizer_train()\n",
    "cv3_test = StemmedCountVectorizer_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf technique\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Without stop_words and stemming\n",
    "tf1 = TfidfVectorizer()\n",
    "\n",
    "# With stop_words\n",
    "tf2 = TfidfVectorizer(analyzer = 'word',stop_words='english')\n",
    "\n",
    "# With stemming\n",
    "import nltk.stem\n",
    "\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "class StemmedTfidf_train(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidf_train, self).build_analyzer()\n",
    "        return lambda train_reviews: ([stemmer.stem(w) for w in analyzer(train_reviews)])\n",
    "\n",
    "class StemmedTfidf_test(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidf_test, self).build_analyzer()\n",
    "        return lambda test_reviews: ([stemmer.stem(w) for w in analyzer(test_reviews)])\n",
    "\n",
    "tf3_train = StemmedTfidf_train()\n",
    "tf3_test = StemmedTfidf_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "X_train = cv1.fit_transform(train_reviews) \n",
    "X_test = cv1.transform(test_reviews)\n",
    "\n",
    "X_label = []\n",
    "X_acc = []\n",
    "X_pres = []\n",
    "X_recall = []\n",
    "X_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitc Regression\n",
    "lr = LogisticRegression(max_iter=7600)\n",
    "lr.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "import seaborn as sn\n",
    "result_matrix = confusion_matrix(Y_test, y_pred)\n",
    "ax= plt.subplot()\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "labels = ['0','1']\n",
    "sn.heatmap(result_matrix, xticklabels=labels, yticklabels=labels, annot=True, fmt=\"1\", linewidths=1.0, square=1)\n",
    "ax.set_xlabel('Predicted Class');ax.set_ylabel('True Class');\n",
    "\n",
    "X_label.append(\"LRcv1\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"SVMcv1\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"KNNcv1\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "X_train = cv2.fit_transform(train_reviews) \n",
    "X_test = cv2.transform(test_reviews) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitc Regression\n",
    "lr = LogisticRegression(max_iter=7600)\n",
    "lr.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"LRcv2\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"SVMcv2\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"KNNcv2\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3\n",
    "X_train = cv3_train.fit_transform(train_reviews) \n",
    "X_test = cv3_train.transform(test_reviews) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logisitc Regression\n",
    "lr = LogisticRegression(max_iter=7600)\n",
    "lr.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"LRcv3\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"SVMcv3\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"KNNcv3\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4\n",
    "X_train = tf1.fit_transform(train_reviews) \n",
    "X_test = tf1.transform(test_reviews) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logisitc Regression\n",
    "lr = LogisticRegression(max_iter=7600)\n",
    "lr.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"LRtf1\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"SVMtf1\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"KNNtf1\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 5\n",
    "X_train = tf2.fit_transform(train_reviews) \n",
    "X_test = tf2.transform(test_reviews) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitc Regression\n",
    "lr = LogisticRegression(max_iter=7600)\n",
    "lr.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"LRtf2\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"SVMtf2\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"KNNtf2\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 6\n",
    "X_train = tf3_train.fit_transform(train_reviews) \n",
    "X_test = tf3_train.transform(test_reviews) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logisitc Regression\n",
    "lr = LogisticRegression(max_iter=7600)\n",
    "lr.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"LRtf3\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"SVMtf3\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, Y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred,digits=4))\n",
    "\n",
    "X_label.append(\"KNNtf3\")\n",
    "X_acc.append(accuracy_score(Y_test, y_pred))\n",
    "X_pres.append(precision_score(Y_test, y_pred))\n",
    "X_recall.append(recall_score(Y_test, y_pred))\n",
    "X_f1.append(f1_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_label)\n",
    "print(X_acc)\n",
    "print(X_pres)\n",
    "print(X_recall)\n",
    "print(X_f1)\n",
    "\n",
    "\n",
    "    \n",
    "#plt.hist([X_acc, X_pres, X_recall, X_f1], bins, label=X_label[0])\n",
    "plt.bar(X_label[:10],X_acc[:10], width = 0.75, color = \"blue\")\n",
    "plt.bar(X_label[9:],X_acc[9:], width = 0.75, color = \"purple\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.title(\"Accuracy Scores\",fontsize=15)\n",
    "plt.ylim(0.5,0.9)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(X_label[:10],X_pres[:10], width = 0.75, color = \"red\")\n",
    "plt.bar(X_label[9:],X_pres[9:], width = 0.75, color = \"orange\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.title(\"Precision Scores\",fontsize=15)\n",
    "plt.ylim(0.5,0.9)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(X_label[:10],X_recall[:10], width = 0.75, color = \"green\")\n",
    "plt.bar(X_label[9:],X_recall[9:], width = 0.75, color = \"limegreen\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.title(\"Recall Scores\",fontsize=15)\n",
    "plt.ylim(0.5,0.9)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(X_label[:10],X_f1[:10], width = 0.75, color = \"teal\")\n",
    "plt.bar(X_label[9:],X_f1[9:], width = 0.75, color = \"lime\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.title(\"F1 Scores\",fontsize=15)\n",
    "plt.ylim(0.5,0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "BoW = []\n",
    "Tfidf = []\n",
    "\n",
    "retrie = [\"Bag of Words\",\"TFIDF\"]\n",
    "stat = [\"Accuarcy\",\"Precision\",\"Recall\",\"F1\"]\n",
    "\n",
    "BoW.append(Average(X_acc[:10]))\n",
    "Tfidf.append(Average(X_acc[9:]))\n",
    "BoW.append(Average(X_pres[:10]))\n",
    "Tfidf.append(Average(X_pres[9:]))\n",
    "BoW.append(Average(X_recall[:10]))\n",
    "Tfidf.append(Average(X_recall[9:]))\n",
    "BoW.append(Average(X_f1[:10]))\n",
    "Tfidf.append(Average(X_f1[9:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BoW,Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app1 = plt.bar(stat,BoW, width = 0.25, align = \"edge\", color = \"teal\")\n",
    "app2 = plt.bar(stat,Tfidf, width = 0.25, color = \"gold\")\n",
    "plt.legend(retrie)\n",
    "plt.title(\"Bag of Words v. TFIDF\",fontsize=15)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.ylim(0.7,0.825)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_label = X_label.copy()\n",
    "\n",
    "new_acc = X_acc.copy()\n",
    "\n",
    "print(new_acc)\n",
    "print(new_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [2,4,6,8,10,12]\n",
    "\n",
    "for i in range(len(num)):\n",
    "    new_label.pop(num[i])\n",
    "    new_acc.pop(num[i])\n",
    "    \n",
    "print(new_acc)\n",
    "print(new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr = [\"Bag of Words\",\"TFIDF\"]\n",
    "\n",
    "plt.bar(X_label[:7],X_acc[:7], width = 0.75, color = \"teal\")\n",
    "plt.bar(X_label[6:],X_acc[6:], width = 0.75, color = \"gold\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.title(\"Accuracy Scores (w/o KNN)\",fontsize=15)\n",
    "plt.ylim(0.82,0.88)\n",
    "plt.legend(appr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defa = new_acc.copy()\n",
    "stop = new_acc.copy()\n",
    "stem = new_acc.copy()\n",
    "\n",
    "num1=[2,2,2,2,4,4,4,4]\n",
    "num2=[0,0,2,2,2,2,4,4]\n",
    "num3=[0,0,0,0,2,2,2,2]\n",
    "\n",
    "for i in range(len(num1)):\n",
    "    defa.pop(num1[i])\n",
    "    \n",
    "for i in range(len(num2)):\n",
    "    stop.pop(num2[i])\n",
    "    \n",
    "for i in range(len(num3)):\n",
    "    stem.pop(num3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(defa,stop,stem)\n",
    "avg_all = []\n",
    "avg_all.append(Average(defa))\n",
    "avg_all.append(Average(stop))\n",
    "avg_all.append(Average(stem))\n",
    "\n",
    "print(avg_all)\n",
    "\n",
    "method = [\"No Filters\",\"Stop\",\"Stemming\"]\n",
    "\n",
    "app1 = plt.bar(method,avg_all, width = 0.75, color = \"navy\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.title(\"Average Accuracy of Filter Methods\",fontsize=15)\n",
    "plt.ylim(0.83,0.87)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
